(window.webpackJsonp=window.webpackJsonp||[]).push([[195],{1160:function(t,l,s){"use strict";s.r(l);var i=s(15),a=Object(i.a)({},(function(){var t=this,l=t.$createElement,s=t._self._c||l;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"elasticsearch-对于大数据量-上亿量级-的聚合如何实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-对于大数据量-上亿量级-的聚合如何实现"}},[t._v("#")]),t._v(" Elasticsearch 对于大数据量（上亿量级）的聚合如何实现")]),t._v(" "),s("p",[t._v("Elasticsearch 提供的首个近似聚合是 cardinality 度量")]),t._v(" "),s("ul",[s("li",[t._v("它提供一个字段的基数，即该字段的 distinct或者 unique 值的数目")]),t._v(" "),s("li",[t._v("它是基于 HLL 算法的\n"),s("ul",[s("li",[t._v("HLL 会先对输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数")]),t._v(" "),s("li",[t._v("特点\n"),s("ul",[s("li",[t._v("可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）")]),t._v(" "),s("li",[t._v("小的数据集精度是非常高")])])]),t._v(" "),s("li",[t._v("可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与配置的精确度相关")])])])])])}),[],!1,null,null,null);l.default=a.exports}}]);